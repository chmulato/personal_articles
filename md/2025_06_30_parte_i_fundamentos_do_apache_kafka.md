# Parte I: Fundamentos do Apache Kafka

![Apache Kafka com Java - Gerenciamento de Filas](/articles/assets/img/2025_06_30_IMAGE_001.png)

## Entendendo os Conceitos Essenciais do Message Broker Mais Popular

Esta parte apresenta os conceitos essenciais do Apache Kafka, sua arquitetura, principais componentes e comandos b√°sicos para quem est√° come√ßando.

---

## O que √© Apache Kafka?

Apache Kafka √© uma plataforma distribu√≠da de streaming de eventos, projetada para alta performance, escalabilidade e toler√¢ncia a falhas. √â amplamente utilizada para processamento de dados em tempo real, integra√ß√£o entre sistemas e pipelines de dados.

## Conceitos Principais

- **Broker**: Servidor Kafka respons√°vel por armazenar e entregar mensagens.
- **Topic**: Canal l√≥gico onde as mensagens s√£o publicadas e consumidas.
- **Partition**: Subdivis√£o de um t√≥pico para escalabilidade e paralelismo.
- **Producer**: Aplica√ß√£o que envia mensagens para o Kafka.
- **Consumer**: Aplica√ß√£o que l√™ mensagens do Kafka.
- **Consumer Group**: Grupo de consumidores que compartilham a leitura de parti√ß√µes.
- **Offset**: Posi√ß√£o sequencial de uma mensagem dentro de uma parti√ß√£o.

## Arquitetura B√°sica

1. Producers publicam mensagens em t√≥picos.
2. Brokers armazenam as mensagens.
3. Consumers leem as mensagens dos t√≥picos.
4. O Kafka garante alta disponibilidade e escalabilidade por meio de parti√ß√µes e replica√ß√£o.

## Instala√ß√£o R√°pida com Docker

Para come√ßar rapidamente, voc√™ pode usar Docker para criar um ambiente Kafka completo:

```bash
# Crie uma rede para os containers
docker network create kafka-net

# Inicie o Zookeeper
docker run -d --name zookeeper --network kafka-net -e ZOOKEEPER_CLIENT_PORT=2181 confluentinc/cp-zookeeper:7.3.0

# Inicie o Kafka
docker run -d --name kafka --network kafka-net -p 9092:9092 \
    -e KAFKA_BROKER_ID=1 \
    -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
    -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092 \
    -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT \
    -e KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT \
    -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
    confluentinc/cp-kafka:7.3.0
```

## Comandos B√°sicos

### Criando um T√≥pico

```bash
docker exec -it kafka kafka-topics --create --topic meu-topico --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1
```

### Listando T√≥picos

```bash
docker exec -it kafka kafka-topics --list --bootstrap-server kafka:29092
```

### Descrevendo um T√≥pico

```bash
docker exec -it kafka kafka-topics --describe --topic meu-topico --bootstrap-server kafka:29092
```

### Produzindo Mensagens

```bash
docker exec -it kafka kafka-console-producer --topic meu-topico --bootstrap-server kafka:29092
> Mensagem 1
> Mensagem 2
> Mensagem 3
```

### Consumindo Mensagens

```bash
docker exec -it kafka kafka-console-consumer --topic meu-topico --from-beginning --bootstrap-server kafka:29092
```

## Configura√ß√µes Importantes

### Reten√ß√£o de Mensagens

O Kafka mant√©m as mensagens por um per√≠odo configur√°vel:

```bash
# Configurar reten√ß√£o para 7 dias
docker exec -it kafka kafka-configs --alter --entity-type topics --entity-name meu-topico --add-config retention.ms=604800000 --bootstrap-server kafka:29092
```

### N√∫mero de Parti√ß√µes

O n√∫mero ideal de parti√ß√µes depende do paralelismo desejado:

```bash
# Aumentar n√∫mero de parti√ß√µes
docker exec -it kafka kafka-topics --alter --topic meu-topico --partitions 6 --bootstrap-server kafka:29092
```

## Monitoramento B√°sico

### Verificando Consumer Groups

```bash
docker exec -it kafka kafka-consumer-groups --list --bootstrap-server kafka:29092
```

### Verificando Offsets de um Consumer Group

```bash
docker exec -it kafka kafka-consumer-groups --describe --group meu-grupo --bootstrap-server kafka:29092
```

## Dicas e Melhores Pr√°ticas

1. **Particionamento adequado**: Escolha um n√∫mero de parti√ß√µes que permita escalabilidade.
2. **Chaves de particionamento**: Use chaves para garantir ordena√ß√£o de mensagens relacionadas.
3. **Replica√ß√£o**: Em ambientes de produ√ß√£o, use fator de replica√ß√£o >= 3.
4. **Monitoramento**: Implemente monitoramento para identificar problemas cedo.
5. **Gerenciamento de esquemas**: Considere usar Avro ou Protobuf com Schema Registry.

## Ferramentas √öteis

- **Conduktor**: Interface gr√°fica para gerenciamento de clusters Kafka.
- **Kafka Tool**: Ferramenta desktop para visualiza√ß√£o e administra√ß√£o.
- **kcat (anteriormente kafkacat)**: Utilit√°rio de linha de comando vers√°til.

## Exemplos de C√≥digo Simples

### Producer em Java

```java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
producer.send(new ProducerRecord<>("meu-topico", "chave", "valor"));
producer.close();
```

### Consumer em Java

```java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "meu-grupo");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

Consumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Collections.singletonList("meu-topico"));

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("offset = %d, key = %s, value = %s%n", 
                          record.offset(), record.key(), record.value());
    }
}
```

Esses exemplos s√£o apenas para fins did√°ticos e funcionam em ambientes locais com o Kafka rodando no padr√£o (localhost:9092).

## Exerc√≠cios Pr√°ticos

Para praticar e aprofundar os conceitos desta parte, consulte tamb√©m o arquivo auxiliar:

- `parte1-fundamentos/exercicios-parte1.md` ‚Äî Exerc√≠cios de fundamentos, comandos b√°sicos, experimenta√ß√£o inicial e espa√ßo para anota√ß√µes.

## C√≥digo-Fonte e Exemplos

Todo o conte√∫do, exemplos pr√°ticos e arquivos de configura√ß√£o deste artigo est√£o dispon√≠veis no reposit√≥rio oficial do projeto no GitHub:

[**üîó github.com/chmulato/kafka-java-mastery**](https://github.com/chmulato/kafka-java-mastery)

**Acesse, explore e contribua!**

#ApacheKafka #Java #Messaging #EventStreaming #DataStreaming #Microservices #Integration #RealTimeData

[![Christian Mulato](/articles/assets/img/foto_chri.jpg)](https://www.linkedin.com/in/chmulato/)
