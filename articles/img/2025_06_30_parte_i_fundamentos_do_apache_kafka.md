---
title: "Parte I - Fundamentos Do Apache Kafka"
date: "30/06/2025"
author: "Christian Mulato"
description: "Artigo t√©cnico sobre parte i - fundamentos do apache kafka"
category: "Java & Spring"
tags: ['Java', 'Spring', 'Docker', 'APIs', 'Maven', 'Kafka']
featured_image: "img/2025_06_30_parte_i_fundamentos_do_apache_kafka_featured.jpg"
---

# Parte I - Fundamentos Do Apache Kafka

![Apache Kafka com Java - Gerenciamento de Filas.](img/image_not_found.png)

Apache Kafka com Java \- Gerenciamento de Filas\.

__Parte I: Fundamentos do Apache Kafka__

__[![Christian Mulato, #OPEN_TO_WORK](img/image_not_found.png)](https://www.linkedin.com/in/chmulato/)__

__[Christian Mulato¬†](https://www.linkedin.com/in/chmulato/)__

Desenvolvedor Java S√™nior | Especialista em Back\-end | Jakarta, Spring Boot, REST APIs, Docker | Engenheiro Qu√≠mico

30 de junho de 2025

__Introdu√ß√£o__

Esta parte apresenta os conceitos essenciais do Apache Kafka, sua arquitetura, principais componentes e comandos b√°sicos para quem est√° come√ßando\.

__O que √© Apache Kafka?__

Apache Kafka √© uma plataforma distribu√≠da de streaming de eventos, projetada para alta performance, escalabilidade e toler√¢ncia a falhas\. √â amplamente utilizada para processamento de dados em tempo real, integra√ß√£o entre sistemas e pipelines de dados\.

__Conceitos Principais__

- Broker: Servidor Kafka respons√°vel por armazenar e entregar mensagens\.
- Topic: Canal l√≥gico onde as mensagens s√£o publicadas e consumidas\.
- Partition: Subdivis√£o de um t√≥pico para escalabilidade e paralelismo\.
- Producer: Aplica√ß√£o que envia mensagens para o Kafka\.
- Consumer: Aplica√ß√£o que l√™ mensagens do Kafka\.
- Consumer Group: Grupo de consumidores que compartilham a leitura de parti√ß√µes\.
- Offset: Posi√ß√£o sequencial de uma mensagem dentro de uma parti√ß√£o\.

__Arquitetura B√°sica__

1. Producers publicam mensagens em t√≥picos\.
2. Brokers armazenam as mensagens\.
3. Consumers leem as mensagens dos t√≥picos\.
4. O Kafka garante alta disponibilidade e escalabilidade por meio de parti√ß√µes e replica√ß√£o\.

__Instala√ß√£o R√°pida com Docker__

docker\-compose up \-d

__Comandos Essenciais__

- Criar um t√≥pico:

kafka\-topics \-\-create \-\-topic meu\-topico \-\-bootstrap\-server localhost:9092 \-\-partitions 3 \-\-replication\-factor 1

- Produzir mensagens:

kafka\-console\-producer \-\-topic meu\-topico \-\-bootstrap\-server localhost:9092

- Consumir mensagens:

kafka\-console\-consumer \-\-topic meu\-topico \-\-from\-beginning \-\-bootstrap\-server localhost:9092

__Exerc√≠cios Pr√°ticos__

1. Suba o ambiente Kafka localmente\.
2. Crie t√≥picos com diferentes n√∫meros de parti√ß√µes\.
3. Produza e consuma mensagens usando o terminal\.
4. Experimente criar m√∫ltiplos consumidores em um mesmo grupo\.

__Recursos Recomendados__

- [__Documenta√ß√£o Oficial do Apache Kafka__](https://kafka.apache.org/documentation/)
- Livro: Kafka: The Definitive Guide \(O'Reilly\)

__Exemplo Java: Producer e Consumer Simples__

A seguir, voc√™ encontra exemplos did√°ticos de um Producer e um Consumer em Java, ideais para quem est√° come√ßando a experimentar o Apache Kafka na pr√°tica\. Os arquivos completos est√£o dispon√≠veis em: parte1\-fundamentos/src/main/java/SimpleProducer\.java e parte1\-fundamentos/src/main/java/SimpleConsumer\.java\.

__Como executar os exemplos__

1. __Garanta que o Kafka est√° rodando em __localhost:9092

Utilize o docker\-compose\.yml fornecido na pasta parte1\-fundamentos/ para subir o ambiente local rapidamente:

docker\-compose up \-d

2\. __Crie o t√≥pico __meu\-topico se necess√°rio

Execute o comando abaixo para criar o t√≥pico no seu cluster Kafka local:

docker exec \-it <nome\_do\_container\_kafka> kafka\-topics \-\-bootstrap\-server localhost:9092 \-\-create \-\-topic meu\-topico \-\-partitions 1 \-\-replication\-factor 1

Substitua <nome\_do\_container\_kafka> pelo nome real do container Kafka em execu√ß√£o \(ex: kafka ou kafka1\)\.

3\. __Compile e execute os exemplos Java usando Maven__

O projeto j√° possui um pom\.xml pronto na pasta parte1\-fundamentos com todas as depend√™ncias necess√°rias\. Basta rodar:

mvn compile

mvn exec:java \-Dexec\.mainClass=SimpleProducer

mvn exec:java \-Dexec\.mainClass=SimpleConsumer

O __SimpleProducer __envia uma mensagem de exemplo para o t√≥pico, e o __SimpleConsumer __consome e imprime as mensagens recebidas\.

__Producer Java ‚Äî Enviando uma mensagem__

O Producer √© respons√°vel por publicar mensagens em um t√≥pico Kafka\. Veja um exemplo b√°sico:

import org\.apache\.kafka\.clients\.producer\.KafkaProducer;

import org\.apache\.kafka\.clients\.producer\.ProducerRecord;

import java\.util\.Properties;

public class SimpleProducer \{

    public static void main\(String\[\] args\) \{

        Properties props = new Properties\(\);

        props\.put\("bootstrap\.servers", "localhost:9092"\);

        props\.put\("key\.serializer", "org\.apache\.kafka\.common\.serialization\.StringSerializer"\);

        props\.put\("value\.serializer", "org\.apache\.kafka\.common\.serialization\.StringSerializer"\);

        try \(KafkaProducer<String, String> producer = new KafkaProducer<>\(props\)\) \{

            producer\.send\(new ProducerRecord<>\("meu\-topico", "mensagem de exemplo"\)\);

            System\.out\.println\("Mensagem enviada\!"\);

        \}

    \}

\}

__Consumer Java ‚Äî Lendo mensagens do t√≥pico__

O Consumer √© respons√°vel por ler as mensagens publicadas em um t√≥pico\. Veja um exemplo b√°sico:

import org\.apache\.kafka\.clients\.consumer\.ConsumerRecords;

import org\.apache\.kafka\.clients\.consumer\.KafkaConsumer;

import org\.apache\.kafka\.clients\.consumer\.ConsumerRecord;

import java\.util\.Collections;

import java\.util\.Properties;

public class SimpleConsumer \{

    public static void main\(String\[\] args\) \{

        Properties props = new Properties\(\);

        props\.put\("bootstrap\.servers", "localhost:9092"\);

        props\.put\("group\.id", "grupo\-exemplo"\);

        props\.put\("key\.deserializer", "org\.apache\.kafka\.common\.serialization\.StringDeserializer"\);

        props\.put\("value\.deserializer", "org\.apache\.kafka\.common\.serialization\.StringDeserializer"\);

        try \(KafkaConsumer<String, String> consumer = new KafkaConsumer<>\(props\)\) \{

            consumer\.subscribe\(Collections\.singletonList\("meu\-topico"\)\);

            ConsumerRecords<String, String> records = consumer\.poll\(java\.time\.Duration\.ofSeconds\(5\)\);

            for \(ConsumerRecord<String, String> record : records\) \{

                System\.out\.printf\("Recebido: %s%n", record\.value\(\)\);

            \}

        \}

    \}

\}

__Dica:__ Voc√™ pode modificar os exemplos para enviar e consumir m√∫ltiplas mensagens, testar diferentes t√≥picos ou experimentar com m√∫ltiplos consumidores para entender o funcionamento dos consumer groups\.

Esses exemplos s√£o apenas para fins did√°ticos e funcionam em ambientes locais com o Kafka rodando no padr√£o \(localhost:9092\)\.

__Exerc√≠cios Pr√°ticos__

Para praticar e aprofundar os conceitos desta parte, consulte tamb√©m o arquivo auxiliar:

- parte1\-fundamentos/exercicios\-parte1\.md ‚Äî Exerc√≠cios de fundamentos, comandos b√°sicos, experimenta√ß√£o inicial e espa√ßo para anota√ß√µes\.

__C√≥digo\-Fonte e Exemplos__

Todo o conte√∫do, exemplos pr√°ticos e arquivos de configura√ß√£o deste artigo est√£o dispon√≠veis no reposit√≥rio oficial do projeto no GitHub:

[__üîó__](https://github.com/chmulato/kafka-java-mastery) [__github\.com/chmulato/kafka\-java\-mastery__](http://github.com/chmulato/kafka-java-mastery)

__Acesse, explore e contribua\!__

