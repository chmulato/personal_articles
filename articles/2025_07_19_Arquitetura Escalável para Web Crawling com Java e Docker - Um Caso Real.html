<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Artigo técnico sobre arquitetura escalável para web crawling com java e docker: um caso real">
    <meta name="author" content="Christian Mulato">
    <meta name="keywords" content="Java, Docker, Containers, Arquitetura, Design Patterns">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Arquitetura Escalável para Web Crawling com Java e Docker: Um Caso Real">
    <meta property="og:description" content="Artigo técnico sobre arquitetura escalável para web crawling com java e docker: um caso real">
    <meta property="og:type" content="article">
    <meta property="og:author" content="Christian Mulato">
    <meta property="og:article:published_time" content="19/07/2025">
    
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Arquitetura Escalável para Web Crawling com Java e Docker: Um Caso Real">
    <meta name="twitter:description" content="Artigo técnico sobre arquitetura escalável para web crawling com java e docker: um caso real">
    
    <title>Arquitetura Escalável para Web Crawling com Java e Docker: Um Caso Real | Christian Mulato Dev Blog</title>
    
    <!-- Fonts e Styles -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=Fira+Code:wght@300;400;500;600&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/article.css">
    
    <!-- Prism.js para syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism-tomorrow.min.css" rel="stylesheet">
    
    <!-- Schema.org structured data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "Arquitetura Escalável para Web Crawling com Java e Docker: Um Caso Real",
        "description": "Artigo técnico sobre arquitetura escalável para web crawling com java e docker: um caso real",
        "author": {
            "@type": "Person",
            "name": "Christian Mulato"
        },
        "datePublished": "19/07/2025",
        "category": "Java & Spring"
    }
    </script>
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="../index.html" class="nav-brand">← Voltar ao Blog</a>
            <div class="nav-links">
                <a href="../index.html">Artigos</a>
                <a href="https://www.linkedin.com/in/chmulato/" target="_blank">LinkedIn</a>
                <a href="https://github.com/chmulato" target="_blank">GitHub</a>
            </div>
        </div>
    </nav>

    <article class="article-container">
        <header class="article-header">
            <div class="article-meta">
                <span class="category">Java & Spring</span>
                <time class="date" datetime="19/07/2025">19/07/2025</time>
            </div>
            <h1 class="article-title">Arquitetura Escalável para Web Crawling com Java e Docker: Um Caso Real</h1>
            <div class="author-info">
                <span>Por <a href="https://www.linkedin.com/in/chmulato/" target="_blank">Christian Mulato</a></span>
            </div>
            <div class="article-tags">
                <span class="tag">Java</span> <span class="tag">Docker</span> <span class="tag">Containers</span> <span class="tag">Arquitetura</span> <span class="tag">Design Patterns</span>
            </div>
        </header>
        
        <div class="article-content">
            <p><img alt="Extraia dados da web com eficiência: veja como uma API moderna com Java e Docker resolve esse desafio." src="img/2025_07_19_Arquitetura Escalável para Web Crawling com Java e Docker - Um Caso Real_image5.jpg" /></p>
<p>Extraia dados da web com eficiência: veja como uma API moderna com Java e Docker resolve esse desafio.</p>
<p>Arquitetura Escalável para Web Crawling com Java e Docker: Um Caso Real</p>
<p><img alt="Christian Mulato, #OPEN_TO_WORK" src="img/2025_07_19_Arquitetura Escalável para Web Crawling com Java e Docker - Um Caso Real_image6.jpg" /></p>
<p>Christian Mulato</p>
<p>Desenvolvedor Java Sênior | Especialista em Back-end | Jakarta, Spring Boot, REST APIs, Docker | Engenheiro Químico</p>
<p>19 de julho de 2025</p>
<p>Como projetar um sistema de crawling moderno, assíncrono e escalável com Spring Boot, RabbitMQ e Docker</p>
<p>Introdução</p>
<p>Neste artigo, apresento a arquitetura por trás da Web Crawler API, um projeto open source construído em Java que realiza buscas inteligentes e paralelas na web. Ele foi desenvolvido para ser confiável, observável e facilmente escalável, aproveitando o melhor do ecossistema Spring, mensageria com RabbitMQ e infraestrutura com Docker/Kubernetes.</p>
<p>Uma História para Entender a Aplicação</p>
<p>Imagine que você está pesquisando sobre "novas tecnologias em energia solar". Você entra em dezenas de sites, blogs e fóruns, abrindo página por página manualmente e procurando por qualquer menção relevante. Isso pode levar horas, dias ou até semanas.</p>
<p>Agora, imagine que você tem um assistente digital, super-rápido, que consegue fazer isso em segundos. Você diz a ele: "procure por 'energia solar bifacial' em todos os sites especializados". Esse assistente então visita automaticamente centenas de páginas, lê o conteúdo e te entrega uma lista com todas as URLs que contêm esse termo.</p>
<p>Esse é o papel da Web Crawler API: um sistema automatizado que pode ser usado por empresas, pesquisadores ou desenvolvedores para encontrar conteúdo específico na web, de forma segura, escalável e com resultados em tempo real.</p>
<p>Motivação</p>
<p>A maioria dos crawlers é feita com scripts monolíticos que não escalam, falham silenciosamente ou geram sobrecarga no servidor alvo. O objetivo aqui foi criar uma API REST moderna, com:</p>
<ul>
<li>Processamento assíncrono</li>
<li>Escalabilidade horizontal</li>
<li>Separação de responsabilidades</li>
<li>Monitoramento e logs estruturados</li>
<li>Deploy simplificado com Docker</li>
</ul>
<p>Visão Geral da Arquitetura</p>
<p>┌───────────────┐     ┌───────────────┐     ┌───────────────┐</p>
<p>│   Controller  │ ─▶ │   Service     │ ─▶  │   RabbitMQ    │</p>
<p>│ (API REST)    │     │ (Negócio)     │     │ (Fila de Tarefas)</p>
<p>└───────────────┘     └───────────────┘     └───────────────┘</p>
<p>▼</p>
<p>┌──────────────┐</p>
<p>│    Worker    │</p>
<p>│ (Crawling)   │</p>
<p>└──────────────┘</p>
<p>▼</p>
<p>Banco de Dados H2</p>
<p>Componentes Principais</p>
<p>Spring Boot 3.x</p>
<p>Framework principal da aplicação, usando:</p>
<ul>
<li>Spring Web: criação da API REST</li>
<li>Spring Data JPA: abstração da camada de dados</li>
<li>Spring AMQP: integração com RabbitMQ</li>
<li>Spring Actuator: métricas e health check</li>
</ul>
<p>RabbitMQ</p>
<p>Message broker que permite:</p>
<ul>
<li>Execução assíncrona</li>
<li>Retentativa em falhas</li>
<li>Paralelismo com múltiplos workers</li>
</ul>
<p>JSoup</p>
<p>Parser HTML usado pelos workers para extrair e analisar conteúdo das páginas.</p>
<p>Docker e Docker Compose</p>
<p>Permitem:</p>
<ul>
<li>Ambientes isolados para testes/desenvolvimento</li>
<li>Execução de todos os serviços com um comando</li>
</ul>
<p>docker-compose up --build -d</p>
<p>Fluxo de Execução</p>
<ol>
<li>Cliente envia POST /crawl com um termo de busca</li>
<li>API gera um ID único e envia mensagem ao RabbitMQ</li>
<li>Worker escuta fila, inicia o crawling</li>
<li>URLs contendo o termo são armazenadas</li>
<li>Cliente pode consultar progresso em tempo real com GET /crawl/{id}</li>
</ol>
<p>Escalabilidade</p>
<ul>
<li>Workers são stateless → podem ser replicados horizontalmente</li>
<li>RabbitMQ suporta múltiplas filas e concorrência alta</li>
<li>Separação entre API e crawler → desacoplamento total</li>
</ul>
<p>Observabilidade</p>
<ul>
<li>Logs estruturados (Spring Boot + Logback)</li>
<li>Health checks e métricas em /actuator</li>
<li>RabbitMQ com painel web (localhost:15672)</li>
<li>Swagger UI para testes interativos da API</li>
</ul>
<p>Testes e Qualidade</p>
<ul>
<li>Cobertura de código: &gt;90% com JUnit 5, Mockito, Testcontainers</li>
<li>Validação de regras de negócio e concorrência</li>
<li>Execução:</li>
</ul>
<p>mvn test</p>
<p>mvn jacoco:report</p>
<p>Deploy</p>
<ul>
<li>Local: Docker Compose</li>
<li>Produção: Kubernetes com Helm</li>
</ul>
<p>helm install crawler-api ./helm/web-crawler-api</p>
<p>Conclusão</p>
<p>A arquitetura escalável e desacoplada da Web Crawler API mostra como é possível construir sistemas robustos com tecnologias modernas do ecossistema Java. O uso de mensageria e containers garante performance e manutenibilidade, enquanto a separação de responsabilidades facilita testes, observação e evolução contínua.</p>
<p>➡️ Projeto completo no GitHub: github.com/chmulato/web-crawler-api</p>
<p>Autor: Christian Vladimir Uhdre Mulato</p>
<p>LinkedIn · GitHub · Campo Largo, PR - Brasil</p>
        </div>
    </article>

    <footer class="article-footer">
        <div class="footer-content">
            <p>&copy; 2025 Christian Mulato. Todos os direitos reservados.</p>
            <div class="footer-links">
                <a href="https://www.linkedin.com/in/chmulato/" target="_blank">LinkedIn</a>
                <a href="https://github.com/chmulato" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>
    
    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- Copy code functionality -->
    <script>
        // Adicionar botões de copiar código
        document.querySelectorAll('pre code').forEach((block) => {
            const button = document.createElement('button');
            button.className = 'copy-button';
            button.textContent = 'Copiar';
            button.onclick = () => {
                navigator.clipboard.writeText(block.textContent);
                button.textContent = 'Copiado!';
                setTimeout(() => button.textContent = 'Copiar', 2000);
            };
            block.parentNode.appendChild(button);
        });
    </script>
</body>
</html>